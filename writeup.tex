\documentclass{article}
\usepackage{graphicx} % Required for inserting images\
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\newtheorem{definition}{Definition}

\title{Go By Vibes}
\author{Misha Lvovsky}
\date{August 2023}

\begin{document}

\maketitle

\section{Problem Statement}

We want to create a smooth embedding space which is analogous to our joint space.
Let's define that a neighborhood in our embedding space has a size of $1$ unit. This means that within $1$ unit all actions and states should be similar and should yield similar results. We can tie these vicinities together by saying that a certain vicinity should correspond with a certain amount of elapsed time. A certain action should be in the vicinity of another action if the resultant states they reach from a given source state are themselves in the same smaller vicinity.

\section{Spaces}

\begin{definition} [State Space] Let $\mathcal{S}$ signify the space of all possible states for the system.
\end{definition}
\begin{definition} [Action Space]
    Let $\mathcal{A}$ signify the space of all possible actions the agent can make
\end{definition}
\begin{definition} [Embedding Space]
    Let $\mathcal{Z}^s$ and $\mathcal{Z}^a$ signify the space of all possible embeddings of states and actions respectively.
\end{definition}

\section{Loss Functions}

% $\mathcal{L}_\text{info}=-\sum\limits_{i} \sum\limits_{j} D_{KL}\left(p_\theta(z^s_i|s_{i}) \| p_\theta(z^s_j|s_{j})\right)-\sum\limits_{i} \sum\limits_{j} D_{KL}\left(p_\theta(z^a_i|a_{i}) \| p_\theta(z^a_j|a_{j})\right)$\\
The first loss functions simply encourages the latent states and actions to be related to the actual states and actions.
The log avoids the gradient vanishing, and the sigmoid prevents it from exploding.
$$\mathcal{L}_\text{state reconstruction} = -\text{sigmoid}(\log(p_\theta(s|z^s))), z^s \sim p_\theta(z^s | s)$$
$$\mathcal{L}_\text{action reconstruction} = -\text{sigmoid}(\log(p_\theta(a|z^a))), z^a \sim p_\theta(z^a | a)$$
The next loss function trains a latent dynamics model to propogate the dynamics in the latent space.
Additionally when applied to the state and action encoders this loss function encourages the states and actions to encode enough information about the state and action to predict the next state.
$$\mathcal{L}_{\text{forward}} = D_{KL}\left( p_\psi\left({z^s}'\middle|z^s,z^a\right) \parallel p_\theta\left({z^s}'\middle| s\right) \right)$$ \\
Next we create a loss function which encourages the states and actions in latent space to be smooth with respect to the transition function.
This means that small perturbations in the latent source state and action input to the forward model should result in proportionally small changes to the resultant precticted next state.
$$\mathcal{L_\text{smooth}}= -\sum\limits_i^N p({z^s_i}'|\mu={z^s_\mu}',\sigma^2=\mathbf{I}), {z^s_i}' \sim p({z^s_i}'|z^s_i,z^a_i)$$
Additionally we want the gradient descent in the space of states and actions to achieve desired next states to be smooth.
In order to encourage the space that has this property we will push nearby states and actions towards having similar jacobians through the latent forward model.
The way we will do this is by sampling \(N\) latent state action pairs in the neighborhood of a source latent state action \(z^{sa}_\mu\) and stacking them into a vector \(\mathbf{z}^{sa}_{0:N-1}\).
We will now take this vector and feed it through the latent forward model to get the predicted next latent states \(\mathbf{z}^{s'}_{0:N-1}\).
We will now take the jacobians of each latent state in \(\mathbf{z}^{s'}_{0:N-1}\) w.r.t. the latent state actions and stack them into the tensors \(\mathbf{j}^{\frac{z^{s'}}{z^{sa}}}_{0:N-1}/\)
We will now make an operation which is analogous taking the standard deviation of the jacobian matrices in the stack.
First we find the mean jacobian \(j^{\frac{z^{s'}}{z^{sa}}}_\mu = \frac{1}{N}\sum\limits_{i=0}^{N-1} \mathbf{j}^{\frac{z^{s'}}{z^{sa}}}_{i}\).
Now we can find the standard deviation of the jacobian matrices by taking the norm of the difference between each jacobian matrix and the mean jacobian matrix.
$$\mathcal{L_\text{gradients smooth}}= \sum\limits_i = \|j^{\frac{z^{s'}}{z^{sa}}}_\mu - j^{\frac{z^{s'}}{z^{sa}}}_i\|_F$$

% $$\mathcal{L_\text{state regularization}}=-\sum\limits_i\max(\|{z_i^s}'-z_i^s\|-\lambda_\text{state}, 0)^2$$
% $\mathcal{L}_\text{action regularization}=-\sum\limits_{i,j} \max(\|z'^s_{i,j}-z^s_i\| - \lambda_\text{act}, 0)^2, z_{i,j}'^s\sim p(z'^s_{i,j}|z^s_i,z^a_{i,j}),z^a_{i,j}\sim p(z^a_{i,j}|\mu=z^a_i, \sigma^2=\lambda_\text{act}^2)$

\section{Network Losses}

$\mathcal{L}_\text{action encoder}=\mathcal{L}_\text{forward} + \mathcal{L}_\text{smooth}+\mathcal{L}_\text{reconstruction}$

% Formalize more what you're trying to achieve here, what does SMOOTHNESS mean

% Describe what expirements you're running in the overleaf

\section{Controller}

\begin{definition}[Trajectory Generator]
    $f: \mathcal{X} \rightarrow \mathcal{S}^H$
\end{definition}
\begin{definition}[Latent Dynamics]
    $d: \mathcal{Z}^s \times \left(\mathcal{Z}^a\right)^H \rightarrow (\mathcal{Z}^s)^H$
\end{definition}
\begin{definition}[Cost Function]
    $j: (\mathcal{S} \times \mathcal{A})^H \rightarrow \mathbb{R}$
\end{definition}
\begin{definition}[Control Plan]
    A sequence $\mathbf{z^a} = \{z^a_0, z^a_1, ..., z^a_{H-1}\}$ where each $z^a_i \in \mathcal{Z}^a$ represents an action taken at time step $i$
\end{definition}
\begin{definition}[Control Cost]
    $c(\mathbf{z}_{0:H-1}^s, \mathbf{z}_{0:H-1}^{s*}) = \sum\limits_{i=0}^{H-1} \| z^s_i\ - z^{s*}_i \|_2^2$
\end{definition}

\begin{algorithm}[H]
    \caption{Latent Trajectory Optimization}
    \label{alg:lto}
    \begin{algorithmic}[1]
        \Require Initial state \(s_0\), initial guess for actions \(\mathbf{z}_{1:H-1}^a\), initial guess for input \(\mathcal{X}\), cost function \(c(\cdot)\), learning rate \(\eta\)
        \Ensure Optimal control sequence \(\mathbf{z}_{1:H-1}^{\text{opt}}\)

        \Function{LatentTrajectoryOptimization}{$s_0$, $\mathbf{z}_{1:H-1}^a$, $c(\cdot)$, $\mathcal{X}$, $\eta$}
        % Algorithm steps
        \Repeat
        \State Generate Target States: \(\mathbf{z}_{1:H}^{s*} = f(\mathcal{X})\)
        \State Do Latent Rollout: \(\mathbf{z}_{0:H-1}^s = d(s_0, \mathbf{z}_{0:H-1}^a)\)
        \State Evaluate Control Cost: \(c = c(\mathbf{z}_{0:H-1}^s, \mathbf{z}_{0:H-1}^{s*})\)
        \State Decode States and Actions: \(\mathbf{s}_{0:H-1} = g(\mathbf{z}_{0:H-1}^s), \mathbf{a}_{0:H-1} = g(\mathbf{z}_{0:H-1}^a)\)
        \State Evaluate Cost Function: \(j = j(\mathbf{z}^s_{0:H-1}, )\)
        \State Compute Gradients:
        \State \hspace{\algorithmicindent} Reached States w.r.t. Target States: \(\nabla_{{\mathbf{z}^s}^*}\mathbf{z}^s = \frac{\partial d}{\partial{\mathbf{z}^s}^*}\)
        \State \hspace{\algorithmicindent} Control Cost w.r.t. Reached States \(\nabla_{\mathbf{z}^s} c = \frac{\partial c}{\partial\mathbf{z}^s}\)
        \State \hspace{\algorithmicindent} Control Cost w.r.t. Actions \(\nabla_{\mathbf{z}^a} c = \frac{\partial c}{\partial \mathbf{z}^a}\)
        \State \hspace{\algorithmicindent} Cost Function w.r.t. Reached States \(\nabla_{\mathbf{z}^s} j = \frac{\partial j}{\partial \mathbf{z}^s}\)
        \State Propagate gradients through trajectory generator: \(\nabla_{\mathcal{X}} = (\nabla_{\mathbf{z}^s} c + \nabla_{\mathbf{z}^s}j ) \left( \nabla_{{\mathbf{z}^s}^*}{\mathbf{z}^s} \right) \left(\frac{\partial f}{\partial \mathcal{X}} \right)\)
        \State Adjust latent actions: \(\mathbf{z}_{1:H-1}^a = \mathbf{z}_{1:H-1}^a - \eta \nabla_{\mathbf{z}^a} c\)
        \State Adjust input to trajectory generator: \(\mathcal{X} = \mathcal{X} - \eta \nabla_{\mathcal{X}}\)
        \Until{Converged}

        \State \Return \(\mathbf{z}_{1:H-1}^{\text{opt}} = \mathbf{z}_{1:H-1}^a\)
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\end{document}
